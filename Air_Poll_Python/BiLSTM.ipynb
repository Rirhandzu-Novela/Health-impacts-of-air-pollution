{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab942aec",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470399a",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('SecundaIM.csv', sep =';', header=0, index_col=0)\n",
    "values = dataset.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ff20a",
   "metadata": {},
   "source": [
    "## Plot pm2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5279d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(values[:,0])\n",
    "plt.ylabel(dataset.columns[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426c6c6",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We need a way to prepare the data for whatever way we would like to formulate the problem.\n",
    "\n",
    "In this case we are formulating it such that we take in 1 time step input (14 variables) and output 1 time step output (1 variable). In other words we are trying to solve the following question: given the pollution and weather conditions of the previous hour, can we predict the PM2.5 level for the next hour.\n",
    "\n",
    "The single variable we are outputing is the PM2.5 level. Note we also use PM2.5 level in our input.\n",
    "\n",
    "Credit for this code: https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7143e863",
   "metadata": {},
   "source": [
    "## Get column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08215071",
   "metadata": {},
   "source": [
    "##Actually perform the data preparation\n",
    "\n",
    "We scale the values between 0 and 1.\n",
    "\n",
    "The code which converts the data into the suitable way we want, in this case, will produce 14 output variables. In our case we only want to predict PM2.5, that is why we drop the other collumns from the dataframe.\n",
    "\n",
    "Credit for this code: https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68094b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "# We drop these because we are only interested in predicting for a single variable (pollution).\n",
    "# If we don't drop, then we will be predicting for all the variables too!\n",
    "reframed.drop(reframed.columns[[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,]], axis=1, inplace=True)\n",
    "values = reframed.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64db2e9",
   "metadata": {},
   "source": [
    "## View the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d39eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d157f81",
   "metadata": {},
   "source": [
    "## Create X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e4b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = values[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = values[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89422383",
   "metadata": {},
   "source": [
    "## Check the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b733065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8101527",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "\n",
    "The format that Keras expects is [batches, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e57a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0],1,X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f99572",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07631602",
   "metadata": {},
   "source": [
    "## Training, validation and testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eee9cc",
   "metadata": {},
   "source": [
    "## Check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('X_train:',X_train.shape)\n",
    "print ('Y_train:',Y_train.shape)\n",
    "print ()\n",
    "print ('X_val:',X_val.shape)\n",
    "print ('Y_val:',Y_val.shape)\n",
    "print ()\n",
    "print ('X_test:',X_test.shape)\n",
    "print ('Y_test:',Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33607c",
   "metadata": {},
   "source": [
    "## Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8120938",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(56, input_shape=(1, 14))))\n",
    "model.add(Dense(56, activation = 'relu'))\n",
    "model.add(Dense(56, activation = 'relu'))\n",
    "model.add(Dense(56, activation = 'relu'))\n",
    "model.add(Dense(56, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb74ec4",
   "metadata": {},
   "source": [
    "## Print summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbad727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a2da6",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1873ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=40, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f8bba",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af02e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscale(scaled_value):\n",
    "    # if target variable is the first column, then, data_max_[0]\n",
    "    unscaled_value = scaled_value * (scaler.data_max_[0] - scaler.data_min_[0]) + (scaler.data_min_[0])\n",
    "    return unscaled_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = unscale(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tests = unscale(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325a7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ce546",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(Y_tests, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd2a756",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(Y_tests, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e199eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(Y_tests, predictions))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d761f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(Y_tests, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca89299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy testing = {}'.format(np.sum(prediction==Y_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59a485",
   "metadata": {},
   "source": [
    "## Compare prediction and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['font.weight'] = 'bold'\n",
    "plt.plot(Y_tests[0:48], color='blue', label = 'Observed')\n",
    "plt.plot(predictions[0:48], color='red', label = 'Predicted')\n",
    "plt.ylabel('PM10', fontname=\"Times New Roman\", size=20,fontweight=\"bold\")\n",
    "plt.xlabel('Time(Hrs)', fontname=\"Times New Roman\", size=20,fontweight=\"bold\")\n",
    "plt.title('Middelburg BiLSTM', fontname=\"Times New Roman\", size=28,fontweight=\"bold\")\n",
    "legend_properties = {'weight':'bold'}\n",
    "plt.legend(prop=legend_properties)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ec422",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = predictions.flatten() - Y_tests\n",
    "\n",
    "# Calculate quantiles based on actual values\n",
    "quantiles, bins = pd.qcut(Y_tests, q=10, duplicates='drop', retbins=True)\n",
    "\n",
    "# Calculate average error for each quantile\n",
    "quantile_errors = []\n",
    "for i in range(len(bins) - 1):\n",
    "    group_indices = np.where((Y_tests >= bins[i]) & (Y_tests < bins[i+1]))[0]\n",
    "    quantile_errors.append(errors[group_indices].mean())\n",
    "\n",
    "# Round the bin edges for better readability\n",
    "rounded_bins = np.round(bins, decimals=3)\n",
    "\n",
    "# Plot quantiles vs. average errors\n",
    "rcParams['font.weight'] = 'bold'\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(quantiles.categories) + 1), quantile_errors, marker='o')\n",
    "plt.xlabel('Quantile', fontname=\"Times New Roman\", size=20, fontweight=\"bold\")\n",
    "plt.ylabel('Average Error', fontname=\"Times New Roman\", size=20, fontweight=\"bold\")\n",
    "plt.title('Quantile Analysis', fontname=\"Times New Roman\", size=28, fontweight=\"bold\")\n",
    "plt.xticks(range(1, len(quantiles.categories) + 1), [f'{rounded_bins[i]:.3f} - {rounded_bins[i+1]:.3f}' for i in range(len(rounded_bins) - 1)], rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
